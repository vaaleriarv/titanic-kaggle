{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos los datos originales del Titanic para luego limpiarlos y preparar las variables para el modelo.\n",
        "Esto es fundamental para evitar problemas con valores faltantes y para transformar variables categóricas en numéricas.\n"
      ],
      "metadata": {
        "id": "O9R8diHDf41A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Subir archivos train.csv y test.csv desde tu equipo\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Cargar los datasets en dataframes\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n"
      ],
      "metadata": {
        "id": "R5uhpg-9f3Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estas transformaciones aseguran que el modelo reciba solo valores numéricos y que variables cualitativas relevantes se consideren, además de manejar los valores faltantes para no perder datos importantes.\n"
      ],
      "metadata": {
        "id": "lwqLcqIFg61f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rellenar valores nulos en 'Age' y 'Fare' con la mediana para evitar sesgos\n",
        "train['Age'].fillna(train['Age'].median(), inplace=True)\n",
        "test['Age'].fillna(test['Age'].median(), inplace=True)\n",
        "test['Fare'].fillna(test['Fare'].median(), inplace=True)\n",
        "\n",
        "# Rellenar valores nulos en 'Embarked' con la moda (valor más frecuente)\n",
        "train['Embarked'].fillna(train['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Crear una nueva variable 'FamilySize' sumando 'SibSp' y 'Parch' + 1 (persona misma)\n",
        "train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
        "test['FamilySize'] = test['SibSp'] + test['Parch'] + 1\n",
        "\n",
        "# Extraer el título del nombre para obtener una variable categórica relevante (ej. Mr, Mrs)\n",
        "for df in [train, test]:\n",
        "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "    # Agrupar títulos poco comunes bajo 'Rare' para evitar ruido\n",
        "    df['Title'] = df['Title'].replace(['Lady', 'Countess', 'Capt', 'Col',\n",
        "                                       'Don', 'Dr', 'Major', 'Rev', 'Sir',\n",
        "                                       'Jonkheer', 'Dona'], 'Rare')\n",
        "    df['Title'] = df['Title'].replace({'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'})\n",
        "\n",
        "# Mapear títulos a números para que el modelo los entienda\n",
        "title_map = {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Rare': 4}\n",
        "train['Title'] = train['Title'].map(title_map)\n",
        "test['Title'] = test['Title'].map(title_map)\n",
        "\n",
        "# Rellenar posibles valores faltantes en títulos\n",
        "train['Title'].fillna(4, inplace=True)\n",
        "test['Title'].fillna(4, inplace=True)\n",
        "\n",
        "# Crear variable 'Deck' basada en la letra inicial de la cabina, mapeándola a números\n",
        "train['Deck'] = train['Cabin'].astype(str).str[0]\n",
        "test['Deck'] = test['Cabin'].astype(str).str[0]\n",
        "\n",
        "deck_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'T': 7, 'n': 8}\n",
        "train['Deck'] = train['Deck'].map(deck_map)\n",
        "test['Deck'] = test['Deck'].map(deck_map)\n",
        "\n",
        "# Mapear variables categóricas 'Sex' y 'Embarked' a valores numéricos\n",
        "sex_map = {'male': 0, 'female': 1}\n",
        "train['Sex'] = train['Sex'].map(sex_map)\n",
        "test['Sex'] = test['Sex'].map(sex_map)\n",
        "\n",
        "embarked_map = {'S': 0, 'C': 1, 'Q': 2}\n",
        "train['Embarked'] = train['Embarked'].map(embarked_map)\n",
        "test['Embarked'] = test['Embarked'].map(embarked_map)"
      ],
      "metadata": {
        "id": "qtu7wnESg3Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos solo el dataset de entrenamiento real de Kaggle (sin usar los datos de test para entrenar). Separar una parte para validación nos ayuda a evaluar el modelo de forma justa."
      ],
      "metadata": {
        "id": "iGRFxhikhxzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos las columnas que usaremos como features para entrenar el modelo\n",
        "features = ['Sex', 'Age', 'Deck', 'Pclass', 'Embarked', 'Title', 'FamilySize']\n",
        "X = train[features]        # Variables predictoras\n",
        "y = train['Survived']      # Variable objetivo\n",
        "\n",
        "# Dividir el dataset en datos de entrenamiento y validación (80/20)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "3-NaDvIahu4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Crear y entrenar el modelo RandomForest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predecir y evaluar\n",
        "y_pred = model.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"Precisión del modelo RandomForest: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "YVHZI_vsh2U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Crear y entrenar el modelo XGBoost\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predecir y evaluar\n",
        "y_pred_xgb = xgb_model.predict(X_val)\n",
        "accuracy_xgb = accuracy_score(y_val, y_pred_xgb)\n",
        "print(f\"Precisión del modelo con XGBoost: {accuracy_xgb:.4f}\")\n"
      ],
      "metadata": {
        "id": "r7JFYGCIh4hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Crear el modelo base\n",
        "xgb = XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Definir grilla de hiperparámetros\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 1],\n",
        "    'colsample_bytree': [0.8, 1]\n",
        "}\n",
        "\n",
        "# Configurar GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Ejecutar la búsqueda\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Mostrar mejores parámetros y score\n",
        "print(\"Mejores parámetros encontrados:\")\n",
        "print(grid_search.best_params_)\n",
        "print(f\"Mejor precisión promedio (CV): {grid_search.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "id": "D-7a6ps1ibIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el mejor modelo encontrado\n",
        "X_test = test[features]\n",
        "best_model = grid_search.best_estimator_\n",
        "final_predictions = best_model.predict(X_test)\n",
        "\n",
        "# Crear archivo CSV\n",
        "output = pd.DataFrame({\n",
        "    'PassengerId': test['PassengerId'],\n",
        "    'Survived': final_predictions\n",
        "})\n",
        "\n",
        "# Guardar\n",
        "output.to_csv('mi_prediccion_final_xgboost.csv', index=False)\n",
        "\n",
        "# Descargar CSV\n",
        "from google.colab import files\n",
        "files.download('titanic.csv')\n"
      ],
      "metadata": {
        "id": "dK50k0WQi-_a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}